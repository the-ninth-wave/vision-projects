{
  
    
        "post0": {
            "title": "papers",
            "content": ". . homepage . vision projects . . $ quad$ This notebook details a machine learning pipeline built for a custom dataset. I assembled the dataset from a collection of pdfs, a corpus of scientific documents. Feeding the data into a PyTorch implementation of the Faster R-CNN architecture, I trained the network to draw bounding boxes around labeled equations, those which are referenced throughout the paper. I see this as a small first step towards a more intricate object detection tool for extracting the logical structure of a math paper given its input as a pdf. . training metrics for latest trained model . ( model_weights_7_50e_lightning ) . In either case below, the $x$-axis corresponds to time elapsed in minutes, not epochs. There is no smoothing applied. . validation AP 1 . . validation mAP . . setup . pip installs . !pip3 install --quiet &quot;seaborn&quot; . !pip3 install --quiet --upgrade &quot;pytorch-lightning&quot; . |████████████████████████████████| 925 kB 12.8 MB/s |████████████████████████████████| 596 kB 78.1 MB/s |████████████████████████████████| 282 kB 96.6 MB/s |████████████████████████████████| 125 kB 96.4 MB/s |████████████████████████████████| 829 kB 86.0 MB/s |████████████████████████████████| 1.3 MB 72.2 MB/s |████████████████████████████████| 160 kB 85.6 MB/s |████████████████████████████████| 271 kB 88.7 MB/s Building wheel for future (setup.py) ... done . !pip3 install --quiet &quot;torchmetrics&gt;=0.3&quot; &quot;torchvision&quot; . !pip3 install --quiet PyQt5 . |████████████████████████████████| 8.3 MB 11.5 MB/s |████████████████████████████████| 317 kB 87.8 MB/s |████████████████████████████████| 59.9 MB 69 kB/s . !pip3 install --quiet neptune-contrib . |████████████████████████████████| 74 kB 2.7 MB/s |████████████████████████████████| 278 kB 30.4 MB/s |████████████████████████████████| 52 kB 1.7 MB/s |████████████████████████████████| 180 kB 89.0 MB/s |████████████████████████████████| 131 kB 83.7 MB/s |████████████████████████████████| 8.0 MB 81.7 MB/s |████████████████████████████████| 79 kB 10.4 MB/s |████████████████████████████████| 138 kB 96.9 MB/s |████████████████████████████████| 63 kB 2.2 MB/s |████████████████████████████████| 127 kB 96.6 MB/s |████████████████████████████████| 67 kB 7.2 MB/s |████████████████████████████████| 129 kB 92.9 MB/s Building wheel for neptune-contrib (setup.py) ... done Building wheel for neptune-client (setup.py) ... done Building wheel for strict-rfc3339 (setup.py) ... done ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible. . !pip3 install --quiet --upgrade albumentations . |████████████████████████████████| 102 kB 15.3 MB/s |████████████████████████████████| 47.6 MB 36 kB/s . imports . import os import sys import xml.etree.ElementTree as ET import re import time import itertools import logging import json from collections import OrderedDict import random import math import matplotlib import matplotlib.pyplot as plt import numpy as np import pytorch_lightning as pl from pytorch_lightning import LightningModule, Trainer from pytorch_lightning.metrics.functional import accuracy import seaborn as sns import tabulate import torch import torch.nn as nn from torch.nn import functional as F import torch.optim as optim import torch.utils.data from torch.utils.data import DataLoader, random_split from torchvision import datasets, transforms from IPython.display import HTML, display, set_matplotlib_formats from PIL import Image, ImageDraw from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint import cv2 import matplotlib.pyplot as plt set_matplotlib_formats(&quot;svg&quot;, &quot;pdf&quot;) # For export matplotlib.rcParams[&quot;lines.linewidth&quot;] = 2.0 sns.reset_orig() %matplotlib inline . . global parameters, paths . AVAIL_GPUS = min(1, torch.cuda.device_count()) PDF_PATH = &quot;drive/Othercomputers/Normandie/GitHub/home/datasets/percolation_papers_2/data/papers/pdf&quot; DATASET_DIR = &quot;drive/Othercomputers/Normandie/GitHub/home/datasets/percolation_papers_2/data/papers&quot; DATASET_DIR_DIR = &quot;drive/Othercomputers/Normandie/GitHub/home/datasets/percolation_papers_2/data&quot; . . paper collection, paper, and page objects . pre-torch, data is organized in three python classes, paper_collection_object, paper_object page_object. We can instantiate a paper_collection object given a list of paper names, along with an implicit path to the data. . . class ... paper_collection_object . args of __init__ . list_of_filenames | . attributes . paper_list | pdf_list | num_papers | pages_path | . labels_path | pages | labels | binary_txt_path | . non_empt_indices | total_pages | paper_ranges | . import pandas as pd class paper_collection_object(): def __init__(self, list_of_filenames ): self.paper_list = list_of_filenames # without suffixes self.pdf_list = [ filename + &#39;.pdf&#39; for filename in self.paper_list ] self.num_papers = len( list_of_filenames ) self.pages_path = DATASET_DIR + &#39;/&#39; + &#39;jpg_pages&#39; self.labels_path = DATASET_DIR + &#39;/&#39; + &#39;labels_xml&#39; self.pages = list(sorted(os.listdir(self.pages_path))) self.labels = list(sorted(os.listdir(self.labels_path))) self.binary_txt_path = DATASET_DIR_DIR + &#39;/&#39; + &#39;empty_0_box_1.txt&#39; self.non_empt_indices = self.get_non_empt_indices() self.total_pages = len(self.pages) self.paper_ranges = self.get_paper_ranges() def get_non_empt_indices(self): with open(self.binary_txt_path, &quot;r&quot;) as tf: indicator_list = tf.read().split(&#39; n&#39;) non_empt_indices = [] for i in range(len(indicator_list)): if indicator_list[i] == &#39;1&#39;: non_empt_indices.append(i) return non_empt_indices def get_paper_range(self, paper): # paper is a string paper_indices = [] N = self.total_pages for j in range(N): if paper in self.pages[j]: paper_indices.append(j) else: pass return [ paper_indices[0], paper_indices[-1] ] def get_paper_ranges(self): paper_ranges = [] for paper in self.paper_list: paper_ranges.append( self.get_paper_range(paper) ) return paper_ranges def display_info(self): pdf_dir_ls = list(sorted(os.listdir(PDF_PATH))) list_of_filenames = [ a.split(&quot;.&quot;)[0] for a in pdf_dir_ls ] filenames_df = pd.DataFrame( list_of_filenames, columns=[&#39;papers&#39;] ) print( filenames_df ) . . class methods . get_non_empt_indices( self ) | get_paper_range( self, paper ) | . get_paper_ranges( self ) | display_info( self ) | . . We define three key lists in the cells hidden below. . key lists . PAPER_LIST | INDICES | PAGE_LIST | . This is what the display_info method looks like on the dataset in question. To call it, we introduce the PAPER_LIST used to initialize dataset. . pdf_dir_ls = list(sorted(os.listdir(PDF_PATH))) PAPER_LIST = [ a.split(&quot;.&quot;)[0] for a in pdf_dir_ls ] collection = paper_collection_object( PAPER_LIST ) collection.display_info() . . papers 0 abe_2015_effective 1 aizenman_1983_sharp 2 aizenman_1987_uniqueness 3 aizenman_1998_holder 4 antal_1996_chemical 5 atapour_2010_number 6 beaton_2018_knotting 7 bonato_2020_asymptotics 8 broadbent_1956_percolation 9 campanino_2002_ornstein 10 caraglio_2020_translocation 11 cerf_2015_lower 12 cerf_2018_new 13 coward_2007_algorithmically 14 duminil_2020_upper 15 even_2017_models 16 grimmett_1990_supercritical 17 grimmett_1999_conformal 18 grimmett_1999_entanglement 19 grimmett_1999_inequalities 20 grimmett_2010_plaquettes 21 grimmett_2013_percolation 22 haggstrom_1999_uniqueness 23 holroyd_1997_existence 24 holroyd_1999_existence 25 holroyd_2001_entanglement 26 holroyd_2001_inequalities 27 holroyd_2012_stochastic 28 ishihara_2017_bounds 29 kantor_1988_topological 30 kesten_1986_incipient 31 liggett_1997_domination 32 orlandini_1994_random 33 orlandini_1998_asymptotics 34 panagiotis_2020_analyticity 35 paturej_2019_knots 36 rensburg_1990_topology 37 scharlemann_1990_lectures 38 soteros_1999_linking 39 soteros_2009_brief 40 timar_2011_boundary 41 vandenberg_2019_lower 42 vanrensburg_1990_knot 43 vologodskii_1973_knot . For later initializing the dataset, we record the indices of &quot;non-empty&quot; pages in the full page list in INDICES. . INDICES = collection.non_empt_indices print(INDICES) . . [1, 2, 4, 5, 6, 7, 10, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 68, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 127, 128, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 149, 150, 151, 159, 161, 169, 170, 174, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 188, 189, 190, 200, 201, 202, 203, 205, 206, 207, 208, 213, 214, 226, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 257, 258, 259, 260, 261, 319, 320, 321, 322, 326, 331, 332, 333, 334, 337, 340, 341, 342, 347, 348, 349, 350, 352, 353, 401, 406, 407, 408, 409, 411, 414, 449, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 465, 466, 470, 471, 474, 490, 491, 497, 502, 504, 505, 511, 516, 517, 518, 519, 522, 524, 525, 526, 527, 529, 535, 536, 537, 538, 539, 540, 548, 549, 550, 551, 552, 555, 556, 558, 559, 562, 564, 566, 569, 653, 655, 656, 657, 659, 660, 664, 665, 700, 705, 706, 708, 709, 710, 712, 713, 715, 716, 717, 719, 720, 721, 722, 723, 724, 725, 726, 731, 732, 736, 737, 738, 739, 741, 743, 744, 749, 751, 752, 753, 757, 758, 759, 768, 769, 770, 771, 773, 774, 776, 777, 778, 779, 787, 788, 791, 792, 795, 797, 798, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 830, 831, 832, 833, 834, 835, 841, 842, 844, 846, 850, 851, 852, 853, 869, 870, 872, 873, 874, 875, 876, 877, 878, 879, 880, 882, 883, 884, 885, 887, 903, 904, 905, 906, 907, 908, 909, 910, 911, 915, 917, 918, 919, 920, 925, 926, 927, 928, 932, 936] . Through these indices, we can name specific pages that correspond to these indices. This is PAGE_LIST. . PAGE_LIST = collection.pages print(PAGE_LIST) . . [&#39;abe_2015_effective_0001&#39;, &#39;abe_2015_effective_0002&#39;, &#39;abe_2015_effective_0003&#39;, &#39;abe_2015_effective_0004&#39;, &#39;abe_2015_effective_0005&#39;, &#39;abe_2015_effective_0006&#39;, &#39;abe_2015_effective_0007&#39;, &#39;abe_2015_effective_0008&#39;, &#39;abe_2015_effective_0009&#39;, &#39;abe_2015_effective_0010&#39;, &#39;abe_2015_effective_0011&#39;, &#39;abe_2015_effective_0012&#39;, &#39;aizenman_1983_sharp_0001&#39;, &#39;aizenman_1983_sharp_0002&#39;, &#39;aizenman_1983_sharp_0003&#39;, &#39;aizenman_1983_sharp_0004&#39;, &#39;aizenman_1983_sharp_0005&#39;, &#39;aizenman_1983_sharp_0006&#39;, &#39;aizenman_1983_sharp_0007&#39;, &#39;aizenman_1983_sharp_0008&#39;, &#39;aizenman_1983_sharp_0009&#39;, &#39;aizenman_1983_sharp_0010&#39;, &#39;aizenman_1983_sharp_0011&#39;, &#39;aizenman_1983_sharp_0012&#39;, &#39;aizenman_1983_sharp_0013&#39;, &#39;aizenman_1983_sharp_0014&#39;, &#39;aizenman_1983_sharp_0015&#39;, &#39;aizenman_1983_sharp_0016&#39;, &#39;aizenman_1983_sharp_0017&#39;, &#39;aizenman_1983_sharp_0018&#39;, &#39;aizenman_1983_sharp_0019&#39;, &#39;aizenman_1983_sharp_0020&#39;, &#39;aizenman_1983_sharp_0021&#39;, &#39;aizenman_1983_sharp_0022&#39;, &#39;aizenman_1983_sharp_0023&#39;, &#39;aizenman_1983_sharp_0024&#39;, &#39;aizenman_1983_sharp_0025&#39;, &#39;aizenman_1983_sharp_0026&#39;, &#39;aizenman_1983_sharp_0027&#39;, &#39;aizenman_1983_sharp_0028&#39;, &#39;aizenman_1983_sharp_0029&#39;, &#39;aizenman_1983_sharp_0030&#39;, &#39;aizenman_1983_sharp_0031&#39;, &#39;aizenman_1983_sharp_0032&#39;, &#39;aizenman_1983_sharp_0033&#39;, &#39;aizenman_1983_sharp_0034&#39;, &#39;aizenman_1983_sharp_0035&#39;, &#39;aizenman_1983_sharp_0036&#39;, &#39;aizenman_1983_sharp_0037&#39;, &#39;aizenman_1983_sharp_0038&#39;, &#39;aizenman_1983_sharp_0039&#39;, &#39;aizenman_1983_sharp_0040&#39;, &#39;aizenman_1983_sharp_0041&#39;, &#39;aizenman_1983_sharp_0042&#39;, &#39;aizenman_1983_sharp_0043&#39;, &#39;aizenman_1983_sharp_0044&#39;, &#39;aizenman_1983_sharp_0045&#39;, &#39;aizenman_1983_sharp_0046&#39;, &#39;aizenman_1983_sharp_0047&#39;, &#39;aizenman_1983_sharp_0048&#39;, &#39;aizenman_1983_sharp_0049&#39;, &#39;aizenman_1983_sharp_0050&#39;, &#39;aizenman_1983_sharp_0051&#39;, &#39;aizenman_1983_sharp_0052&#39;, &#39;aizenman_1983_sharp_0053&#39;, &#39;aizenman_1987_uniqueness_0001&#39;, &#39;aizenman_1987_uniqueness_0002&#39;, &#39;aizenman_1987_uniqueness_0003&#39;, &#39;aizenman_1987_uniqueness_0004&#39;, &#39;aizenman_1987_uniqueness_0005&#39;, &#39;aizenman_1987_uniqueness_0006&#39;, &#39;aizenman_1987_uniqueness_0007&#39;, &#39;aizenman_1987_uniqueness_0008&#39;, &#39;aizenman_1987_uniqueness_0009&#39;, &#39;aizenman_1987_uniqueness_0010&#39;, &#39;aizenman_1987_uniqueness_0011&#39;, &#39;aizenman_1987_uniqueness_0012&#39;, &#39;aizenman_1987_uniqueness_0013&#39;, &#39;aizenman_1987_uniqueness_0014&#39;, &#39;aizenman_1987_uniqueness_0015&#39;, &#39;aizenman_1987_uniqueness_0016&#39;, &#39;aizenman_1987_uniqueness_0017&#39;, &#39;aizenman_1987_uniqueness_0018&#39;, &#39;aizenman_1987_uniqueness_0019&#39;, &#39;aizenman_1987_uniqueness_0020&#39;, &#39;aizenman_1987_uniqueness_0021&#39;, &#39;aizenman_1987_uniqueness_0022&#39;, &#39;aizenman_1987_uniqueness_0023&#39;, &#39;aizenman_1987_uniqueness_0024&#39;, &#39;aizenman_1987_uniqueness_0025&#39;, &#39;aizenman_1987_uniqueness_0026&#39;, &#39;aizenman_1987_uniqueness_0027&#39;, &#39;aizenman_1987_uniqueness_0028&#39;, &#39;aizenman_1998_holder_0001&#39;, &#39;aizenman_1998_holder_0002&#39;, &#39;aizenman_1998_holder_0003&#39;, &#39;aizenman_1998_holder_0004&#39;, &#39;aizenman_1998_holder_0005&#39;, &#39;aizenman_1998_holder_0006&#39;, &#39;aizenman_1998_holder_0007&#39;, &#39;aizenman_1998_holder_0008&#39;, &#39;aizenman_1998_holder_0009&#39;, &#39;aizenman_1998_holder_0010&#39;, &#39;aizenman_1998_holder_0011&#39;, &#39;aizenman_1998_holder_0012&#39;, &#39;aizenman_1998_holder_0013&#39;, &#39;aizenman_1998_holder_0014&#39;, &#39;aizenman_1998_holder_0015&#39;, &#39;aizenman_1998_holder_0016&#39;, &#39;aizenman_1998_holder_0017&#39;, &#39;aizenman_1998_holder_0018&#39;, &#39;aizenman_1998_holder_0019&#39;, &#39;aizenman_1998_holder_0020&#39;, &#39;aizenman_1998_holder_0021&#39;, &#39;aizenman_1998_holder_0022&#39;, &#39;aizenman_1998_holder_0023&#39;, &#39;aizenman_1998_holder_0024&#39;, &#39;aizenman_1998_holder_0025&#39;, &#39;aizenman_1998_holder_0026&#39;, &#39;aizenman_1998_holder_0027&#39;, &#39;aizenman_1998_holder_0028&#39;, &#39;aizenman_1998_holder_0029&#39;, &#39;aizenman_1998_holder_0030&#39;, &#39;aizenman_1998_holder_0031&#39;, &#39;aizenman_1998_holder_0032&#39;, &#39;aizenman_1998_holder_0033&#39;, &#39;aizenman_1998_holder_0034&#39;, &#39;aizenman_1998_holder_0035&#39;, &#39;aizenman_1998_holder_0036&#39;, &#39;aizenman_1998_holder_0037&#39;, &#39;aizenman_1998_holder_0038&#39;, &#39;aizenman_1998_holder_0039&#39;, &#39;aizenman_1998_holder_0040&#39;, &#39;aizenman_1998_holder_0041&#39;, &#39;antal_1996_chemical_0001&#39;, &#39;antal_1996_chemical_0002&#39;, &#39;antal_1996_chemical_0003&#39;, &#39;antal_1996_chemical_0004&#39;, &#39;antal_1996_chemical_0005&#39;, &#39;antal_1996_chemical_0006&#39;, &#39;antal_1996_chemical_0007&#39;, &#39;antal_1996_chemical_0008&#39;, &#39;antal_1996_chemical_0009&#39;, &#39;antal_1996_chemical_0010&#39;, &#39;antal_1996_chemical_0011&#39;, &#39;antal_1996_chemical_0012&#39;, &#39;antal_1996_chemical_0013&#39;, &#39;atapour_2010_number_0001&#39;, &#39;atapour_2010_number_0002&#39;, &#39;atapour_2010_number_0003&#39;, &#39;atapour_2010_number_0004&#39;, &#39;atapour_2010_number_0005&#39;, &#39;atapour_2010_number_0006&#39;, &#39;atapour_2010_number_0007&#39;, &#39;atapour_2010_number_0008&#39;, &#39;atapour_2010_number_0009&#39;, &#39;atapour_2010_number_0010&#39;, &#39;atapour_2010_number_0011&#39;, &#39;atapour_2010_number_0012&#39;, &#39;atapour_2010_number_0013&#39;, &#39;atapour_2010_number_0014&#39;, &#39;atapour_2010_number_0015&#39;, &#39;atapour_2010_number_0016&#39;, &#39;atapour_2010_number_0017&#39;, &#39;atapour_2010_number_0018&#39;, &#39;atapour_2010_number_0019&#39;, &#39;atapour_2010_number_0020&#39;, &#39;atapour_2010_number_0021&#39;, &#39;atapour_2010_number_0022&#39;, &#39;atapour_2010_number_0023&#39;, &#39;atapour_2010_number_0024&#39;, &#39;atapour_2010_number_0025&#39;, &#39;atapour_2010_number_0026&#39;, &#39;beaton_2018_knotting_0001&#39;, &#39;beaton_2018_knotting_0002&#39;, &#39;beaton_2018_knotting_0003&#39;, &#39;beaton_2018_knotting_0004&#39;, &#39;beaton_2018_knotting_0005&#39;, &#39;beaton_2018_knotting_0006&#39;, &#39;beaton_2018_knotting_0007&#39;, &#39;beaton_2018_knotting_0008&#39;, &#39;beaton_2018_knotting_0009&#39;, &#39;beaton_2018_knotting_0010&#39;, &#39;beaton_2018_knotting_0011&#39;, &#39;beaton_2018_knotting_0012&#39;, &#39;beaton_2018_knotting_0013&#39;, &#39;beaton_2018_knotting_0014&#39;, &#39;beaton_2018_knotting_0015&#39;, &#39;beaton_2018_knotting_0016&#39;, &#39;beaton_2018_knotting_0017&#39;, &#39;beaton_2018_knotting_0018&#39;, &#39;beaton_2018_knotting_0019&#39;, &#39;beaton_2018_knotting_0020&#39;, &#39;beaton_2018_knotting_0021&#39;, &#39;beaton_2018_knotting_0022&#39;, &#39;beaton_2018_knotting_0023&#39;, &#39;beaton_2018_knotting_0024&#39;, &#39;bonato_2020_asymptotics_0001&#39;, &#39;bonato_2020_asymptotics_0002&#39;, &#39;bonato_2020_asymptotics_0003&#39;, &#39;bonato_2020_asymptotics_0004&#39;, &#39;bonato_2020_asymptotics_0005&#39;, &#39;bonato_2020_asymptotics_0006&#39;, &#39;bonato_2020_asymptotics_0007&#39;, &#39;bonato_2020_asymptotics_0008&#39;, &#39;bonato_2020_asymptotics_0009&#39;, &#39;bonato_2020_asymptotics_0010&#39;, &#39;bonato_2020_asymptotics_0011&#39;, &#39;bonato_2020_asymptotics_0012&#39;, &#39;bonato_2020_asymptotics_0013&#39;, &#39;bonato_2020_asymptotics_0014&#39;, &#39;bonato_2020_asymptotics_0015&#39;, &#39;bonato_2020_asymptotics_0016&#39;, &#39;bonato_2020_asymptotics_0017&#39;, &#39;bonato_2020_asymptotics_0018&#39;, &#39;bonato_2020_asymptotics_0019&#39;, &#39;bonato_2020_asymptotics_0020&#39;, &#39;bonato_2020_asymptotics_0021&#39;, &#39;broadbent_1956_percolation_0001&#39;, &#39;broadbent_1956_percolation_0002&#39;, &#39;broadbent_1956_percolation_0003&#39;, &#39;broadbent_1956_percolation_0004&#39;, &#39;broadbent_1956_percolation_0005&#39;, &#39;broadbent_1956_percolation_0006&#39;, &#39;broadbent_1956_percolation_0007&#39;, &#39;broadbent_1956_percolation_0008&#39;, &#39;broadbent_1956_percolation_0009&#39;, &#39;broadbent_1956_percolation_0010&#39;, &#39;broadbent_1956_percolation_0011&#39;, &#39;broadbent_1956_percolation_0012&#39;, &#39;broadbent_1956_percolation_0013&#39;, &#39;broadbent_1956_percolation_0014&#39;, &#39;campanino_2002_ornstein_0001&#39;, &#39;campanino_2002_ornstein_0002&#39;, &#39;campanino_2002_ornstein_0003&#39;, &#39;campanino_2002_ornstein_0004&#39;, &#39;campanino_2002_ornstein_0005&#39;, &#39;campanino_2002_ornstein_0006&#39;, &#39;campanino_2002_ornstein_0007&#39;, &#39;campanino_2002_ornstein_0008&#39;, &#39;campanino_2002_ornstein_0009&#39;, &#39;campanino_2002_ornstein_0010&#39;, &#39;campanino_2002_ornstein_0011&#39;, &#39;campanino_2002_ornstein_0012&#39;, &#39;campanino_2002_ornstein_0013&#39;, &#39;campanino_2002_ornstein_0014&#39;, &#39;campanino_2002_ornstein_0015&#39;, &#39;campanino_2002_ornstein_0016&#39;, &#39;campanino_2002_ornstein_0017&#39;, &#39;campanino_2002_ornstein_0018&#39;, &#39;campanino_2002_ornstein_0019&#39;, &#39;campanino_2002_ornstein_0020&#39;, &#39;campanino_2002_ornstein_0021&#39;, &#39;campanino_2002_ornstein_0022&#39;, &#39;campanino_2002_ornstein_0023&#39;, &#39;campanino_2002_ornstein_0024&#39;, &#39;campanino_2002_ornstein_0025&#39;, &#39;campanino_2002_ornstein_0026&#39;, &#39;campanino_2002_ornstein_0027&#39;, &#39;campanino_2002_ornstein_0028&#39;, &#39;campanino_2002_ornstein_0029&#39;, &#39;campanino_2002_ornstein_0030&#39;, &#39;campanino_2002_ornstein_0031&#39;, &#39;caraglio_2020_translocation_0001&#39;, &#39;caraglio_2020_translocation_0002&#39;, &#39;caraglio_2020_translocation_0003&#39;, &#39;caraglio_2020_translocation_0004&#39;, &#39;caraglio_2020_translocation_0005&#39;, &#39;caraglio_2020_translocation_0006&#39;, &#39;caraglio_2020_translocation_0007&#39;, &#39;caraglio_2020_translocation_0008&#39;, &#39;caraglio_2020_translocation_0009&#39;, &#39;caraglio_2020_translocation_0010&#39;, &#39;caraglio_2020_translocation_0011&#39;, &#39;caraglio_2020_translocation_0012&#39;, &#39;caraglio_2020_translocation_0013&#39;, &#39;caraglio_2020_translocation_0014&#39;, &#39;caraglio_2020_translocation_0015&#39;, &#39;caraglio_2020_translocation_0016&#39;, &#39;cerf_2015_lower_0001&#39;, &#39;cerf_2015_lower_0002&#39;, &#39;cerf_2015_lower_0003&#39;, &#39;cerf_2015_lower_0004&#39;, &#39;cerf_2015_lower_0005&#39;, &#39;cerf_2015_lower_0006&#39;, &#39;cerf_2015_lower_0007&#39;, &#39;cerf_2015_lower_0008&#39;, &#39;cerf_2015_lower_0009&#39;, &#39;cerf_2015_lower_0010&#39;, &#39;cerf_2015_lower_0011&#39;, &#39;cerf_2015_lower_0012&#39;, &#39;cerf_2015_lower_0013&#39;, &#39;cerf_2015_lower_0014&#39;, &#39;cerf_2015_lower_0015&#39;, &#39;cerf_2015_lower_0016&#39;, &#39;cerf_2015_lower_0017&#39;, &#39;cerf_2015_lower_0018&#39;, &#39;cerf_2015_lower_0019&#39;, &#39;cerf_2015_lower_0020&#39;, &#39;cerf_2015_lower_0021&#39;, &#39;cerf_2015_lower_0022&#39;, &#39;cerf_2015_lower_0023&#39;, &#39;cerf_2018_new_0001&#39;, &#39;cerf_2018_new_0002&#39;, &#39;cerf_2018_new_0003&#39;, &#39;cerf_2018_new_0004&#39;, &#39;cerf_2018_new_0005&#39;, &#39;cerf_2018_new_0006&#39;, &#39;cerf_2018_new_0007&#39;, &#39;cerf_2018_new_0008&#39;, &#39;cerf_2018_new_0009&#39;, &#39;cerf_2018_new_0010&#39;, &#39;cerf_2018_new_0011&#39;, &#39;cerf_2018_new_0012&#39;, &#39;cerf_2018_new_0013&#39;, &#39;cerf_2018_new_0014&#39;, &#39;cerf_2018_new_0015&#39;, &#39;cerf_2018_new_0016&#39;, &#39;cerf_2018_new_0017&#39;, &#39;cerf_2018_new_0018&#39;, &#39;cerf_2018_new_0019&#39;, &#39;cerf_2018_new_0020&#39;, &#39;cerf_2018_new_0021&#39;, &#39;cerf_2018_new_0022&#39;, &#39;cerf_2018_new_0023&#39;, &#39;cerf_2018_new_0024&#39;, &#39;cerf_2018_new_0025&#39;, &#39;cerf_2018_new_0026&#39;, &#39;cerf_2018_new_0027&#39;, &#39;cerf_2018_new_0028&#39;, &#39;cerf_2018_new_0029&#39;, &#39;cerf_2018_new_0030&#39;, &#39;cerf_2018_new_0031&#39;, &#39;cerf_2018_new_0032&#39;, &#39;cerf_2018_new_0033&#39;, &#39;cerf_2018_new_0034&#39;, &#39;cerf_2018_new_0035&#39;, &#39;cerf_2018_new_0036&#39;, &#39;cerf_2018_new_0037&#39;, &#39;cerf_2018_new_0038&#39;, &#39;cerf_2018_new_0039&#39;, &#39;cerf_2018_new_0040&#39;, &#39;cerf_2018_new_0041&#39;, &#39;cerf_2018_new_0042&#39;, &#39;cerf_2018_new_0043&#39;, &#39;cerf_2018_new_0044&#39;, &#39;cerf_2018_new_0045&#39;, &#39;cerf_2018_new_0046&#39;, &#39;cerf_2018_new_0047&#39;, &#39;cerf_2018_new_0048&#39;, &#39;cerf_2018_new_0049&#39;, &#39;cerf_2018_new_0050&#39;, &#39;cerf_2018_new_0051&#39;, &#39;cerf_2018_new_0052&#39;, &#39;cerf_2018_new_0053&#39;, &#39;cerf_2018_new_0054&#39;, &#39;coward_2007_algorithmically_0001&#39;, &#39;coward_2007_algorithmically_0002&#39;, &#39;coward_2007_algorithmically_0003&#39;, &#39;coward_2007_algorithmically_0004&#39;, &#39;coward_2007_algorithmically_0005&#39;, &#39;coward_2007_algorithmically_0006&#39;, &#39;coward_2007_algorithmically_0007&#39;, &#39;coward_2007_algorithmically_0008&#39;, &#39;coward_2007_algorithmically_0009&#39;, &#39;coward_2007_algorithmically_0010&#39;, &#39;coward_2007_algorithmically_0011&#39;, &#39;coward_2007_algorithmically_0012&#39;, &#39;coward_2007_algorithmically_0013&#39;, &#39;coward_2007_algorithmically_0014&#39;, &#39;coward_2007_algorithmically_0015&#39;, &#39;coward_2007_algorithmically_0016&#39;, &#39;coward_2007_algorithmically_0017&#39;, &#39;coward_2007_algorithmically_0018&#39;, &#39;coward_2007_algorithmically_0019&#39;, &#39;coward_2007_algorithmically_0020&#39;, &#39;coward_2007_algorithmically_0021&#39;, &#39;coward_2007_algorithmically_0022&#39;, &#39;coward_2007_algorithmically_0023&#39;, &#39;coward_2007_algorithmically_0024&#39;, &#39;coward_2007_algorithmically_0025&#39;, &#39;coward_2007_algorithmically_0026&#39;, &#39;coward_2007_algorithmically_0027&#39;, &#39;coward_2007_algorithmically_0028&#39;, &#39;coward_2007_algorithmically_0029&#39;, &#39;coward_2007_algorithmically_0030&#39;, &#39;coward_2007_algorithmically_0031&#39;, &#39;coward_2007_algorithmically_0032&#39;, &#39;coward_2007_algorithmically_0033&#39;, &#39;coward_2007_algorithmically_0034&#39;, &#39;coward_2007_algorithmically_0035&#39;, &#39;coward_2007_algorithmically_0036&#39;, &#39;coward_2007_algorithmically_0037&#39;, &#39;coward_2007_algorithmically_0038&#39;, &#39;coward_2007_algorithmically_0039&#39;, &#39;coward_2007_algorithmically_0040&#39;, &#39;coward_2007_algorithmically_0041&#39;, &#39;coward_2007_algorithmically_0042&#39;, &#39;coward_2007_algorithmically_0043&#39;, &#39;coward_2007_algorithmically_0044&#39;, &#39;coward_2007_algorithmically_0045&#39;, &#39;duminil_2020_upper_0001&#39;, &#39;duminil_2020_upper_0002&#39;, &#39;duminil_2020_upper_0003&#39;, &#39;duminil_2020_upper_0004&#39;, &#39;duminil_2020_upper_0005&#39;, &#39;duminil_2020_upper_0006&#39;, &#39;duminil_2020_upper_0007&#39;, &#39;duminil_2020_upper_0008&#39;, &#39;duminil_2020_upper_0009&#39;, &#39;duminil_2020_upper_0010&#39;, &#39;duminil_2020_upper_0011&#39;, &#39;duminil_2020_upper_0012&#39;, &#39;duminil_2020_upper_0013&#39;, &#39;duminil_2020_upper_0014&#39;, &#39;duminil_2020_upper_0015&#39;, &#39;duminil_2020_upper_0016&#39;, &#39;duminil_2020_upper_0017&#39;, &#39;duminil_2020_upper_0018&#39;, &#39;duminil_2020_upper_0019&#39;, &#39;duminil_2020_upper_0020&#39;, &#39;duminil_2020_upper_0021&#39;, &#39;even_2017_models_0001&#39;, &#39;even_2017_models_0002&#39;, &#39;even_2017_models_0003&#39;, &#39;even_2017_models_0004&#39;, &#39;even_2017_models_0005&#39;, &#39;even_2017_models_0006&#39;, &#39;even_2017_models_0007&#39;, &#39;even_2017_models_0008&#39;, &#39;even_2017_models_0009&#39;, &#39;even_2017_models_0010&#39;, &#39;even_2017_models_0011&#39;, &#39;even_2017_models_0012&#39;, &#39;even_2017_models_0013&#39;, &#39;even_2017_models_0014&#39;, &#39;even_2017_models_0015&#39;, &#39;even_2017_models_0016&#39;, &#39;even_2017_models_0017&#39;, &#39;even_2017_models_0018&#39;, &#39;even_2017_models_0019&#39;, &#39;even_2017_models_0020&#39;, &#39;even_2017_models_0021&#39;, &#39;even_2017_models_0022&#39;, &#39;even_2017_models_0023&#39;, &#39;even_2017_models_0024&#39;, &#39;even_2017_models_0025&#39;, &#39;even_2017_models_0026&#39;, &#39;even_2017_models_0027&#39;, &#39;grimmett_1990_supercritical_0001&#39;, &#39;grimmett_1990_supercritical_0002&#39;, &#39;grimmett_1990_supercritical_0003&#39;, &#39;grimmett_1990_supercritical_0004&#39;, &#39;grimmett_1990_supercritical_0005&#39;, &#39;grimmett_1990_supercritical_0006&#39;, &#39;grimmett_1990_supercritical_0007&#39;, &#39;grimmett_1990_supercritical_0008&#39;, &#39;grimmett_1990_supercritical_0009&#39;, &#39;grimmett_1990_supercritical_0010&#39;, &#39;grimmett_1990_supercritical_0011&#39;, &#39;grimmett_1990_supercritical_0012&#39;, &#39;grimmett_1990_supercritical_0013&#39;, &#39;grimmett_1990_supercritical_0014&#39;, &#39;grimmett_1990_supercritical_0015&#39;, &#39;grimmett_1990_supercritical_0016&#39;, &#39;grimmett_1990_supercritical_0017&#39;, &#39;grimmett_1990_supercritical_0018&#39;, &#39;grimmett_1990_supercritical_0019&#39;, &#39;grimmett_1999_conformal_0001&#39;, &#39;grimmett_1999_conformal_0002&#39;, &#39;grimmett_1999_conformal_0003&#39;, &#39;grimmett_1999_conformal_0004&#39;, &#39;grimmett_1999_conformal_0005&#39;, &#39;grimmett_1999_conformal_0006&#39;, &#39;grimmett_1999_conformal_0007&#39;, &#39;grimmett_1999_conformal_0008&#39;, &#39;grimmett_1999_conformal_0009&#39;, &#39;grimmett_1999_conformal_0010&#39;, &#39;grimmett_1999_conformal_0011&#39;, &#39;grimmett_1999_conformal_0012&#39;, &#39;grimmett_1999_conformal_0013&#39;, &#39;grimmett_1999_conformal_0014&#39;, &#39;grimmett_1999_entanglement_0001&#39;, &#39;grimmett_1999_entanglement_0002&#39;, &#39;grimmett_1999_entanglement_0003&#39;, &#39;grimmett_1999_entanglement_0004&#39;, &#39;grimmett_1999_entanglement_0005&#39;, &#39;grimmett_1999_entanglement_0006&#39;, &#39;grimmett_1999_entanglement_0007&#39;, &#39;grimmett_1999_entanglement_0008&#39;, &#39;grimmett_1999_entanglement_0009&#39;, &#39;grimmett_1999_entanglement_0010&#39;, &#39;grimmett_1999_entanglement_0011&#39;, &#39;grimmett_1999_entanglement_0012&#39;, &#39;grimmett_1999_entanglement_0013&#39;, &#39;grimmett_1999_entanglement_0014&#39;, &#39;grimmett_1999_entanglement_0015&#39;, &#39;grimmett_1999_entanglement_0016&#39;, &#39;grimmett_1999_entanglement_0017&#39;, &#39;grimmett_1999_entanglement_0018&#39;, &#39;grimmett_1999_entanglement_0019&#39;, &#39;grimmett_1999_entanglement_0020&#39;, &#39;grimmett_1999_entanglement_0021&#39;, &#39;grimmett_1999_entanglement_0022&#39;, &#39;grimmett_1999_entanglement_0023&#39;, &#39;grimmett_1999_entanglement_0024&#39;, &#39;grimmett_1999_entanglement_0025&#39;, &#39;grimmett_1999_entanglement_0026&#39;, &#39;grimmett_1999_entanglement_0027&#39;, &#39;grimmett_1999_entanglement_0028&#39;, &#39;grimmett_1999_entanglement_0029&#39;, &#39;grimmett_1999_entanglement_0030&#39;, &#39;grimmett_1999_entanglement_0031&#39;, &#39;grimmett_1999_entanglement_0032&#39;, &#39;grimmett_1999_entanglement_0033&#39;, &#39;grimmett_1999_inequalities_0001&#39;, &#39;grimmett_1999_inequalities_0002&#39;, &#39;grimmett_1999_inequalities_0003&#39;, &#39;grimmett_1999_inequalities_0004&#39;, &#39;grimmett_1999_inequalities_0005&#39;, &#39;grimmett_1999_inequalities_0006&#39;, &#39;grimmett_1999_inequalities_0007&#39;, &#39;grimmett_1999_inequalities_0008&#39;, &#39;grimmett_1999_inequalities_0009&#39;, &#39;grimmett_1999_inequalities_0010&#39;, &#39;grimmett_1999_inequalities_0011&#39;, &#39;grimmett_1999_inequalities_0012&#39;, &#39;grimmett_1999_inequalities_0013&#39;, &#39;grimmett_1999_inequalities_0014&#39;, &#39;grimmett_1999_inequalities_0015&#39;, &#39;grimmett_1999_inequalities_0016&#39;, &#39;grimmett_2010_plaquettes_0001&#39;, &#39;grimmett_2010_plaquettes_0002&#39;, &#39;grimmett_2010_plaquettes_0003&#39;, &#39;grimmett_2010_plaquettes_0004&#39;, &#39;grimmett_2010_plaquettes_0005&#39;, &#39;grimmett_2010_plaquettes_0006&#39;, &#39;grimmett_2010_plaquettes_0007&#39;, &#39;grimmett_2010_plaquettes_0008&#39;, &#39;grimmett_2010_plaquettes_0009&#39;, &#39;grimmett_2010_plaquettes_0010&#39;, &#39;grimmett_2010_plaquettes_0011&#39;, &#39;grimmett_2010_plaquettes_0012&#39;, &#39;grimmett_2010_plaquettes_0013&#39;, &#39;grimmett_2010_plaquettes_0014&#39;, &#39;grimmett_2013_percolation_0001&#39;, &#39;grimmett_2013_percolation_0002&#39;, &#39;grimmett_2013_percolation_0003&#39;, &#39;grimmett_2013_percolation_0004&#39;, &#39;grimmett_2013_percolation_0005&#39;, &#39;grimmett_2013_percolation_0006&#39;, &#39;grimmett_2013_percolation_0007&#39;, &#39;grimmett_2013_percolation_0008&#39;, &#39;grimmett_2013_percolation_0009&#39;, &#39;grimmett_2013_percolation_0010&#39;, &#39;grimmett_2013_percolation_0011&#39;, &#39;grimmett_2013_percolation_0012&#39;, &#39;grimmett_2013_percolation_0013&#39;, &#39;grimmett_2013_percolation_0014&#39;, &#39;grimmett_2013_percolation_0015&#39;, &#39;grimmett_2013_percolation_0016&#39;, &#39;grimmett_2013_percolation_0017&#39;, &#39;haggstrom_1999_uniqueness_0001&#39;, &#39;haggstrom_1999_uniqueness_0002&#39;, &#39;haggstrom_1999_uniqueness_0003&#39;, &#39;haggstrom_1999_uniqueness_0004&#39;, &#39;haggstrom_1999_uniqueness_0005&#39;, &#39;haggstrom_1999_uniqueness_0006&#39;, &#39;haggstrom_1999_uniqueness_0007&#39;, &#39;haggstrom_1999_uniqueness_0008&#39;, &#39;haggstrom_1999_uniqueness_0009&#39;, &#39;holroyd_1997_existence_0001&#39;, &#39;holroyd_1997_existence_0002&#39;, &#39;holroyd_1997_existence_0003&#39;, &#39;holroyd_1997_existence_0004&#39;, &#39;holroyd_1997_existence_0005&#39;, &#39;holroyd_1997_existence_0006&#39;, &#39;holroyd_1997_existence_0007&#39;, &#39;holroyd_1997_existence_0008&#39;, &#39;holroyd_1997_existence_0009&#39;, &#39;holroyd_1997_existence_0010&#39;, &#39;holroyd_1997_existence_0011&#39;, &#39;holroyd_1997_existence_0012&#39;, &#39;holroyd_1997_existence_0013&#39;, &#39;holroyd_1997_existence_0014&#39;, &#39;holroyd_1997_existence_0015&#39;, &#39;holroyd_1997_existence_0016&#39;, &#39;holroyd_1997_existence_0017&#39;, &#39;holroyd_1997_existence_0018&#39;, &#39;holroyd_1997_existence_0019&#39;, &#39;holroyd_1997_existence_0020&#39;, &#39;holroyd_1997_existence_0021&#39;, &#39;holroyd_1997_existence_0022&#39;, &#39;holroyd_1997_existence_0023&#39;, &#39;holroyd_1997_existence_0024&#39;, &#39;holroyd_1997_existence_0025&#39;, &#39;holroyd_1997_existence_0026&#39;, &#39;holroyd_1997_existence_0027&#39;, &#39;holroyd_1997_existence_0028&#39;, &#39;holroyd_1997_existence_0029&#39;, &#39;holroyd_1997_existence_0030&#39;, &#39;holroyd_1997_existence_0031&#39;, &#39;holroyd_1997_existence_0032&#39;, &#39;holroyd_1997_existence_0033&#39;, &#39;holroyd_1999_existence_0001&#39;, &#39;holroyd_1999_existence_0002&#39;, &#39;holroyd_1999_existence_0003&#39;, &#39;holroyd_1999_existence_0004&#39;, &#39;holroyd_1999_existence_0005&#39;, &#39;holroyd_1999_existence_0006&#39;, &#39;holroyd_1999_existence_0007&#39;, &#39;holroyd_1999_existence_0008&#39;, &#39;holroyd_1999_existence_0009&#39;, &#39;holroyd_1999_existence_0010&#39;, &#39;holroyd_1999_existence_0011&#39;, &#39;holroyd_1999_existence_0012&#39;, &#39;holroyd_1999_existence_0013&#39;, &#39;holroyd_1999_existence_0014&#39;, &#39;holroyd_1999_existence_0015&#39;, &#39;holroyd_1999_existence_0016&#39;, &#39;holroyd_1999_existence_0017&#39;, &#39;holroyd_1999_existence_0018&#39;, &#39;holroyd_1999_existence_0019&#39;, &#39;holroyd_1999_existence_0020&#39;, &#39;holroyd_1999_existence_0021&#39;, &#39;holroyd_1999_existence_0022&#39;, &#39;holroyd_1999_existence_0023&#39;, &#39;holroyd_1999_existence_0024&#39;, &#39;holroyd_2001_entanglement_0001&#39;, &#39;holroyd_2001_entanglement_0002&#39;, &#39;holroyd_2001_entanglement_0003&#39;, &#39;holroyd_2001_entanglement_0004&#39;, &#39;holroyd_2001_entanglement_0005&#39;, &#39;holroyd_2001_entanglement_0006&#39;, &#39;holroyd_2001_entanglement_0007&#39;, &#39;holroyd_2001_entanglement_0008&#39;, &#39;holroyd_2001_entanglement_0009&#39;, &#39;holroyd_2001_entanglement_0010&#39;, &#39;holroyd_2001_entanglement_0011&#39;, &#39;holroyd_2001_inequalities_0001&#39;, &#39;holroyd_2001_inequalities_0002&#39;, &#39;holroyd_2001_inequalities_0003&#39;, &#39;holroyd_2001_inequalities_0004&#39;, &#39;holroyd_2001_inequalities_0005&#39;, &#39;holroyd_2001_inequalities_0006&#39;, &#39;holroyd_2001_inequalities_0007&#39;, &#39;holroyd_2001_inequalities_0008&#39;, &#39;holroyd_2012_stochastic_0001&#39;, &#39;holroyd_2012_stochastic_0002&#39;, &#39;holroyd_2012_stochastic_0003&#39;, &#39;holroyd_2012_stochastic_0004&#39;, &#39;holroyd_2012_stochastic_0005&#39;, &#39;holroyd_2012_stochastic_0006&#39;, &#39;holroyd_2012_stochastic_0007&#39;, &#39;holroyd_2012_stochastic_0008&#39;, &#39;holroyd_2012_stochastic_0009&#39;, &#39;holroyd_2012_stochastic_0010&#39;, &#39;holroyd_2012_stochastic_0011&#39;, &#39;holroyd_2012_stochastic_0012&#39;, &#39;holroyd_2012_stochastic_0013&#39;, &#39;holroyd_2012_stochastic_0014&#39;, &#39;holroyd_2012_stochastic_0015&#39;, &#39;holroyd_2012_stochastic_0016&#39;, &#39;holroyd_2012_stochastic_0017&#39;, &#39;holroyd_2012_stochastic_0018&#39;, &#39;holroyd_2012_stochastic_0019&#39;, &#39;holroyd_2012_stochastic_0020&#39;, &#39;holroyd_2012_stochastic_0021&#39;, &#39;ishihara_2017_bounds_0001&#39;, &#39;ishihara_2017_bounds_0002&#39;, &#39;ishihara_2017_bounds_0003&#39;, &#39;ishihara_2017_bounds_0004&#39;, &#39;ishihara_2017_bounds_0005&#39;, &#39;ishihara_2017_bounds_0006&#39;, &#39;ishihara_2017_bounds_0007&#39;, &#39;ishihara_2017_bounds_0008&#39;, &#39;ishihara_2017_bounds_0009&#39;, &#39;ishihara_2017_bounds_0010&#39;, &#39;ishihara_2017_bounds_0011&#39;, &#39;ishihara_2017_bounds_0012&#39;, &#39;ishihara_2017_bounds_0013&#39;, &#39;ishihara_2017_bounds_0014&#39;, &#39;ishihara_2017_bounds_0015&#39;, &#39;ishihara_2017_bounds_0016&#39;, &#39;ishihara_2017_bounds_0017&#39;, &#39;ishihara_2017_bounds_0018&#39;, &#39;ishihara_2017_bounds_0019&#39;, &#39;ishihara_2017_bounds_0020&#39;, &#39;ishihara_2017_bounds_0021&#39;, &#39;ishihara_2017_bounds_0022&#39;, &#39;ishihara_2017_bounds_0023&#39;, &#39;ishihara_2017_bounds_0024&#39;, &#39;ishihara_2017_bounds_0025&#39;, &#39;ishihara_2017_bounds_0026&#39;, &#39;ishihara_2017_bounds_0027&#39;, &#39;ishihara_2017_bounds_0028&#39;, &#39;ishihara_2017_bounds_0029&#39;, &#39;kantor_1988_topological_0001&#39;, &#39;kantor_1988_topological_0002&#39;, &#39;kantor_1988_topological_0003&#39;, &#39;kantor_1988_topological_0004&#39;, &#39;kantor_1988_topological_0005&#39;, &#39;kesten_1986_incipient_0001&#39;, &#39;kesten_1986_incipient_0002&#39;, &#39;kesten_1986_incipient_0003&#39;, &#39;kesten_1986_incipient_0004&#39;, &#39;kesten_1986_incipient_0005&#39;, &#39;kesten_1986_incipient_0006&#39;, &#39;kesten_1986_incipient_0007&#39;, &#39;kesten_1986_incipient_0008&#39;, &#39;kesten_1986_incipient_0009&#39;, &#39;kesten_1986_incipient_0010&#39;, &#39;kesten_1986_incipient_0011&#39;, &#39;kesten_1986_incipient_0012&#39;, &#39;kesten_1986_incipient_0013&#39;, &#39;kesten_1986_incipient_0014&#39;, &#39;kesten_1986_incipient_0015&#39;, &#39;kesten_1986_incipient_0016&#39;, &#39;kesten_1986_incipient_0017&#39;, &#39;kesten_1986_incipient_0018&#39;, &#39;kesten_1986_incipient_0019&#39;, &#39;kesten_1986_incipient_0020&#39;, &#39;kesten_1986_incipient_0021&#39;, &#39;kesten_1986_incipient_0022&#39;, &#39;kesten_1986_incipient_0023&#39;, &#39;kesten_1986_incipient_0024&#39;, &#39;kesten_1986_incipient_0025&#39;, &#39;kesten_1986_incipient_0026&#39;, &#39;liggett_1997_domination_0001&#39;, &#39;liggett_1997_domination_0002&#39;, &#39;liggett_1997_domination_0003&#39;, &#39;liggett_1997_domination_0004&#39;, &#39;liggett_1997_domination_0005&#39;, &#39;liggett_1997_domination_0006&#39;, &#39;liggett_1997_domination_0007&#39;, &#39;liggett_1997_domination_0008&#39;, &#39;liggett_1997_domination_0009&#39;, &#39;liggett_1997_domination_0010&#39;, &#39;liggett_1997_domination_0011&#39;, &#39;liggett_1997_domination_0012&#39;, &#39;liggett_1997_domination_0013&#39;, &#39;liggett_1997_domination_0014&#39;, &#39;liggett_1997_domination_0015&#39;, &#39;liggett_1997_domination_0016&#39;, &#39;liggett_1997_domination_0017&#39;, &#39;liggett_1997_domination_0018&#39;, &#39;liggett_1997_domination_0019&#39;, &#39;liggett_1997_domination_0020&#39;, &#39;liggett_1997_domination_0021&#39;, &#39;liggett_1997_domination_0022&#39;, &#39;liggett_1997_domination_0023&#39;, &#39;liggett_1997_domination_0024&#39;, &#39;liggett_1997_domination_0025&#39;, &#39;liggett_1997_domination_0026&#39;, &#39;orlandini_1994_random_0001&#39;, &#39;orlandini_1994_random_0002&#39;, &#39;orlandini_1994_random_0003&#39;, &#39;orlandini_1994_random_0004&#39;, &#39;orlandini_1994_random_0005&#39;, &#39;orlandini_1994_random_0006&#39;, &#39;orlandini_1994_random_0007&#39;, &#39;orlandini_1994_random_0008&#39;, &#39;orlandini_1994_random_0009&#39;, &#39;orlandini_1994_random_0010&#39;, &#39;orlandini_1994_random_0011&#39;, &#39;orlandini_1994_random_0012&#39;, &#39;orlandini_1998_asymptotics_0001&#39;, &#39;orlandini_1998_asymptotics_0002&#39;, &#39;orlandini_1998_asymptotics_0003&#39;, &#39;orlandini_1998_asymptotics_0004&#39;, &#39;orlandini_1998_asymptotics_0005&#39;, &#39;orlandini_1998_asymptotics_0006&#39;, &#39;orlandini_1998_asymptotics_0007&#39;, &#39;orlandini_1998_asymptotics_0008&#39;, &#39;orlandini_1998_asymptotics_0009&#39;, &#39;orlandini_1998_asymptotics_0010&#39;, &#39;orlandini_1998_asymptotics_0011&#39;, &#39;orlandini_1998_asymptotics_0012&#39;, &#39;orlandini_1998_asymptotics_0013&#39;, &#39;orlandini_1998_asymptotics_0014&#39;, &#39;orlandini_1998_asymptotics_0015&#39;, &#39;orlandini_1998_asymptotics_0016&#39;, &#39;panagiotis_2020_analyticity_0001&#39;, &#39;panagiotis_2020_analyticity_0002&#39;, &#39;panagiotis_2020_analyticity_0003&#39;, &#39;panagiotis_2020_analyticity_0004&#39;, &#39;panagiotis_2020_analyticity_0005&#39;, &#39;panagiotis_2020_analyticity_0006&#39;, &#39;panagiotis_2020_analyticity_0007&#39;, &#39;panagiotis_2020_analyticity_0008&#39;, &#39;panagiotis_2020_analyticity_0009&#39;, &#39;panagiotis_2020_analyticity_0010&#39;, &#39;panagiotis_2020_analyticity_0011&#39;, &#39;panagiotis_2020_analyticity_0012&#39;, &#39;panagiotis_2020_analyticity_0013&#39;, &#39;panagiotis_2020_analyticity_0014&#39;, &#39;panagiotis_2020_analyticity_0015&#39;, &#39;panagiotis_2020_analyticity_0016&#39;, &#39;panagiotis_2020_analyticity_0017&#39;, &#39;panagiotis_2020_analyticity_0018&#39;, &#39;panagiotis_2020_analyticity_0019&#39;, &#39;panagiotis_2020_analyticity_0020&#39;, &#39;paturej_2019_knots_0001&#39;, &#39;paturej_2019_knots_0002&#39;, &#39;paturej_2019_knots_0003&#39;, &#39;paturej_2019_knots_0004&#39;, &#39;paturej_2019_knots_0005&#39;, &#39;paturej_2019_knots_0006&#39;, &#39;paturej_2019_knots_0007&#39;, &#39;paturej_2019_knots_0008&#39;, &#39;paturej_2019_knots_0009&#39;, &#39;paturej_2019_knots_0010&#39;, &#39;paturej_2019_knots_0011&#39;, &#39;paturej_2019_knots_0012&#39;, &#39;paturej_2019_knots_0013&#39;, &#39;paturej_2019_knots_0014&#39;, &#39;paturej_2019_knots_0015&#39;, &#39;paturej_2019_knots_0016&#39;, &#39;paturej_2019_knots_0017&#39;, &#39;paturej_2019_knots_0018&#39;, &#39;paturej_2019_knots_0019&#39;, &#39;paturej_2019_knots_0020&#39;, &#39;paturej_2019_knots_0021&#39;, &#39;paturej_2019_knots_0022&#39;, &#39;paturej_2019_knots_0023&#39;, &#39;paturej_2019_knots_0024&#39;, &#39;paturej_2019_knots_0025&#39;, &#39;paturej_2019_knots_0026&#39;, &#39;paturej_2019_knots_0027&#39;, &#39;paturej_2019_knots_0028&#39;, &#39;paturej_2019_knots_0029&#39;, &#39;paturej_2019_knots_0030&#39;, &#39;paturej_2019_knots_0031&#39;, &#39;paturej_2019_knots_0032&#39;, &#39;paturej_2019_knots_0033&#39;, &#39;paturej_2019_knots_0034&#39;, &#39;paturej_2019_knots_0035&#39;, &#39;paturej_2019_knots_0036&#39;, &#39;rensburg_1990_topology_0001&#39;, &#39;rensburg_1990_topology_0002&#39;, &#39;rensburg_1990_topology_0003&#39;, &#39;rensburg_1990_topology_0004&#39;, &#39;rensburg_1990_topology_0005&#39;, &#39;rensburg_1990_topology_0006&#39;, &#39;rensburg_1990_topology_0007&#39;, &#39;rensburg_1990_topology_0008&#39;, &#39;rensburg_1990_topology_0009&#39;, &#39;rensburg_1990_topology_0010&#39;, &#39;rensburg_1990_topology_0011&#39;, &#39;rensburg_1990_topology_0012&#39;, &#39;rensburg_1990_topology_0013&#39;, &#39;rensburg_1990_topology_0014&#39;, &#39;rensburg_1990_topology_0015&#39;, &#39;rensburg_1990_topology_0016&#39;, &#39;rensburg_1990_topology_0017&#39;, &#39;rensburg_1990_topology_0018&#39;, &#39;scharlemann_1990_lectures_0001&#39;, &#39;scharlemann_1990_lectures_0002&#39;, &#39;scharlemann_1990_lectures_0003&#39;, &#39;scharlemann_1990_lectures_0004&#39;, &#39;scharlemann_1990_lectures_0005&#39;, &#39;scharlemann_1990_lectures_0006&#39;, &#39;scharlemann_1990_lectures_0007&#39;, &#39;scharlemann_1990_lectures_0008&#39;, &#39;scharlemann_1990_lectures_0009&#39;, &#39;scharlemann_1990_lectures_0010&#39;, &#39;scharlemann_1990_lectures_0011&#39;, &#39;soteros_1999_linking_0001&#39;, &#39;soteros_1999_linking_0002&#39;, &#39;soteros_1999_linking_0003&#39;, &#39;soteros_1999_linking_0004&#39;, &#39;soteros_1999_linking_0005&#39;, &#39;soteros_1999_linking_0006&#39;, &#39;soteros_1999_linking_0007&#39;, &#39;soteros_1999_linking_0008&#39;, &#39;soteros_1999_linking_0009&#39;, &#39;soteros_1999_linking_0010&#39;, &#39;soteros_1999_linking_0011&#39;, &#39;soteros_1999_linking_0012&#39;, &#39;soteros_1999_linking_0013&#39;, &#39;soteros_1999_linking_0014&#39;, &#39;soteros_1999_linking_0015&#39;, &#39;soteros_1999_linking_0016&#39;, &#39;soteros_1999_linking_0017&#39;, &#39;soteros_1999_linking_0018&#39;, &#39;soteros_1999_linking_0019&#39;, &#39;soteros_1999_linking_0020&#39;, &#39;soteros_1999_linking_0021&#39;, &#39;soteros_1999_linking_0022&#39;, &#39;soteros_1999_linking_0023&#39;, &#39;soteros_2009_brief_0001&#39;, &#39;soteros_2009_brief_0002&#39;, &#39;soteros_2009_brief_0003&#39;, &#39;soteros_2009_brief_0004&#39;, &#39;soteros_2009_brief_0005&#39;, &#39;timar_2011_boundary_0001&#39;, &#39;timar_2011_boundary_0002&#39;, &#39;timar_2011_boundary_0003&#39;, &#39;timar_2011_boundary_0004&#39;, &#39;timar_2011_boundary_0005&#39;, &#39;timar_2011_boundary_0006&#39;, &#39;timar_2011_boundary_0007&#39;, &#39;timar_2011_boundary_0008&#39;, &#39;vandenberg_2019_lower_0001&#39;, &#39;vandenberg_2019_lower_0002&#39;, &#39;vandenberg_2019_lower_0003&#39;, &#39;vandenberg_2019_lower_0004&#39;, &#39;vandenberg_2019_lower_0005&#39;, &#39;vandenberg_2019_lower_0006&#39;, &#39;vandenberg_2019_lower_0007&#39;, &#39;vandenberg_2019_lower_0008&#39;, &#39;vandenberg_2019_lower_0009&#39;, &#39;vandenberg_2019_lower_0010&#39;, &#39;vanrensburg_1990_knot_0001&#39;, &#39;vanrensburg_1990_knot_0002&#39;, &#39;vanrensburg_1990_knot_0003&#39;, &#39;vanrensburg_1990_knot_0004&#39;, &#39;vanrensburg_1990_knot_0005&#39;, &#39;vanrensburg_1990_knot_0006&#39;, &#39;vanrensburg_1990_knot_0007&#39;, &#39;vanrensburg_1990_knot_0008&#39;, &#39;vanrensburg_1990_knot_0009&#39;, &#39;vanrensburg_1990_knot_0010&#39;, &#39;vanrensburg_1990_knot_0011&#39;, &#39;vanrensburg_1990_knot_0012&#39;, &#39;vanrensburg_1990_knot_0013&#39;, &#39;vanrensburg_1990_knot_0014&#39;, &#39;vanrensburg_1990_knot_0015&#39;, &#39;vanrensburg_1990_knot_0016&#39;, &#39;vanrensburg_1990_knot_0017&#39;, &#39;vanrensburg_1990_knot_0018&#39;, &#39;vanrensburg_1990_knot_0019&#39;, &#39;vologodskii_1973_knot_0001&#39;, &#39;vologodskii_1973_knot_0002&#39;, &#39;vologodskii_1973_knot_0003&#39;, &#39;vologodskii_1973_knot_0004&#39;, &#39;vologodskii_1973_knot_0005&#39;] . . class ... paper_object . args of __init__ . paper_collection . | filename . | . attributes . name | parent_collection | pdf_path | num_pages | . names_of_pages | names_of_jpgs | names_of_xmls | . global_pdf_index | global_index_range | non_empty_list | . class paper_object( ): def __init__(self, paper_collection, filename): self.name = filename self.parent_collection = paper_collection self.global_pdf_index = self.get_global_pdf_index() self.pdf_path = PDF_PATH + &#39;/&#39; + filename + &#39;.pdf&#39; self.global_index_range = self.get_global_index_range() self.num_pages = self.global_index_range[1] - self.global_index_range[0] + 1 self.names_of_pages = self.list_page_names() self.names_of_jpgs = [ page_name + &#39;.jpg&#39; for page_name in self.names_of_pages ] self.names_of_xmls = [ page_name + &#39;.xml&#39; for page_name in self.names_of_pages ] self.non_empty_list = self.get_non_empty_list() def zpad_string(self, s, zpadding): s_z = s.zfill(zpadding) return s_z def get_txt_list(self): path = self.txt_path f = open(path, &quot;r&quot;) txt_list = f.readlines() f.close() return(txt_list) def get_num_pages(self): return len(self.names_of_pages) def list_page_names(self): a = self.global_index_range[0] b = self.global_index_range[1] global_index_set = range(a, b+1) names_list = [] for j in global_index_set: page_name = self.parent_collection.pages[j] names_list.append( page_name ) return names_list def get_global_pdf_index(self): collection = self.parent_collection collection_papers = collection.paper_list L = len(collection_papers) for j in range(L): if collection_papers[j] == self.name: index = j return(index) def get_global_index_range(self): collection = self.parent_collection global_pdf_index = self.global_pdf_index collection_ranges = collection.paper_ranges index_range = collection_ranges[ self.global_pdf_index ] return(index_range) def get_non_empty_list(self): index_range = self.global_index_range a = index_range[0] b = index_range[1] collection = self.parent_collection all_non_empt_indices = collection.non_empt_indices paper_non_empt = [ j for j in all_non_empt_indices if (j &gt;= a) and (j &lt;= b) ] return paper_non_empt . . class methods . get_txt_list( self ) | get_num_pages( self ) | list_page_names( self ) | . get_margin_boxes( self, hires ) | get_global_pdf_index( self ) | get_global_index_range( self ) | . get_non_empty_list( self ) | zpad_string( s, zpadding ) | . . . class ... page_object . args of __init__ . paper . | page_number . | . attributes . parent_paper | grandparent_collection | number | jpg_name | xml_name | . jpg_path | xml_path | non_empty | . from PIL import Image class page_object(): def __init__(self, paper, page_number): self.parent_paper = paper self.grandparent_collection = self.parent_paper.parent_collection self.number = page_number self.jpg_name = self.parent_paper.names_of_pages[ self.number - 1 ] self.xml_name = self.parent_paper.names_of_xmls[ self.number - 1 ] self.jpg_path = DATASET_DIR + &#39;/&#39; + &#39;jpg_pages&#39; + &#39;/&#39; + self.jpg_name self.xml_path = DATASET_DIR + &#39;/&#39; + &#39;labels_xml&#39; + &#39;/&#39; + self.xml_name self.non_empty = self.get_non_empty_status() def get_non_empty_status(self): paper = self.parent_paper paper_global_index_range = paper.global_index_range a = paper_global_index_range[0] global_index = a + self.number - 1 if global_index in paper.non_empty_list: return True else: return False def get_RGB(self): page = Image.open(self.jpg_path).convert(&quot;RGB&quot;) trans = transforms.Compose([transforms.ToTensor()]) page_tens = trans(page) #print( page_tens.size() ) #page_pil = Image.fromarray(np.array()).convert(&quot;RGB&quot;) return page def get_target(self): xml_path = self.xml_path xml = ET.parse(xml_path) xml_root = xml.getroot() is_empty = xml_root.tag == &#39;empty&#39; boxes = [] labels = [] iscrowd = [] area = [] if is_empty: # prep boxes, masks, labels boxes_tens = torch.as_tensor(boxes, dtype=torch.float32) boxes_tens = boxes_tens[:,None] labels = torch.as_tensor(labels, dtype = torch.int64) iscrowd = torch.as_tensor(iscrowd, dtype = torch.int64) area = torch.as_tensor(area, dtype= torch.float32) else: # prep boxes xmin_Elements = xml_root.findall(&quot;./object/bndbox/xmin&quot;) xmin = [ np.float(j.text) for j in xmin_Elements ] ymin_Elements = xml_root.findall(&quot;./object/bndbox/ymin&quot;) ymin = [ np.float(j.text) for j in ymin_Elements ] xmax_Elements = xml_root.findall(&quot;./object/bndbox/xmax&quot;) xmax = [ np.float(j.text) for j in xmax_Elements ] ymax_Elements = xml_root.findall(&quot;./object/bndbox/ymax&quot;) ymax = [ np.float(j.text) for j in ymax_Elements ] # The following are heights and widths h = torch.as_tensor(ymax) - torch.as_tensor(ymin) w = torch.as_tensor(xmax) - torch.as_tensor(xmin) # load labels labels = torch.ones( (len(xmin),), dtype = torch.int64) iscrowd = torch.zeros( (len(xmin),), dtype = torch.int64) ## load boxes and recast for j in range(0,len(xmin)): box = [ xmin[j], ymin[j], xmax[j], ymax[j] ] boxes.append(box) area.append( w[j]* h[j] ) #boxes_stack= torch.stack(boxes, dim=0) boxes_tens = torch.as_tensor(boxes, dtype=torch.float32) area = torch.as_tensor(area, dtype=torch.float32) # target target = {} target[&quot;boxes&quot;] = boxes_tens target[&quot;labels&quot;] = labels target[&quot;area&quot;] = area target[&quot;iscrowd&quot;] = iscrowd return target . . class methods . get_non_empty_status( self ) | get_RGB( self ) | get_target( self ) | . . model . . method ... get_fasterRCNN . args . num_classes | . import torchvision from torchvision.models.detection.faster_rcnn import FastRCNNPredictor def get_fasterRCNN(num_classes): model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True) in_features = model.roi_heads.box_predictor.cls_score.in_features model.roi_heads.box_predictor = FastRCNNPredictor( in_features, num_classes ) return model . . . model = get_fasterRCNN(2) . Downloading: &#34;https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth&#34; to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth . transform helpers, torchvision imports . %%shell git clone https://github.com/pytorch/vision.git cd vision git checkout v0.3.0 cp references/detection/utils.py ../ cp references/detection/transforms.py ../ cp references/detection/coco_eval.py ../ cp references/detection/engine.py ../ cp references/detection/coco_utils.py .. . Cloning into &#39;vision&#39;... remote: Enumerating objects: 44087, done. remote: Counting objects: 100% (9561/9561), done. remote: Compressing objects: 100% (2427/2427), done. remote: Total 44087 (delta 7442), reused 8798 (delta 6957), pack-reused 34526 Receiving objects: 100% (44087/44087), 72.31 MiB | 27.34 MiB/s, done. Resolving deltas: 100% (33986/33986), done. Note: checking out &#39;v0.3.0&#39;. You are in &#39;detached HEAD&#39; state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by performing another checkout. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -b with the checkout command again. Example: git checkout -b &lt;new-branch-name&gt; HEAD is now at be376084 version check against PyTorch&#39;s CUDA version . . import utils import albumentations as A . from here . . class ... Compose . class Compose: &quot;&quot;&quot;Baseclass - composes several transforms together.&quot;&quot;&quot; def __init__(self, transforms): self.transforms = transforms def __repr__(self): return str([transform for transform in self.transforms]) . . . . class ... Repr . class Repr: &quot;&quot;&quot;Evaluatable string representation of an object&quot;&quot;&quot; def __repr__(self): return f&quot;{self.__class__.__name__}: {self.__dict__}&quot; . . . . class ... ComposeDouble . class ComposeDouble(Compose): &quot;&quot;&quot;Composes transforms for input-target pairs.&quot;&quot;&quot; def __call__(self, inp: np.ndarray, target: dict): for t in self.transforms: inp, target = t(inp, target) return inp, target . . . . class ... AlbumentationWrapper . class AlbumentationWrapper(Repr): &quot;&quot;&quot; A wrapper for the albumentation package. Bounding boxes are expected to be in xyxy format (pascal_voc). Bounding boxes cannot be larger than the spatial image&#39;s dimensions. Use Clip() if your bounding boxes are outside of the image, before using this wrapper. &quot;&quot;&quot; def __init__(self, albumentation, format: str = &quot;pascal_voc&quot;): self.albumentation = albumentation self.format = format def __call__(self, inp: np.ndarray, tar: dict): # input, target transform = A.Compose( [self.albumentation], bbox_params=A.BboxParams(format=self.format, label_fields=[&quot;class_labels&quot;]), ) out_dict = transform(image=inp, bboxes=tar[&quot;boxes&quot;], class_labels=tar[&quot;labels&quot;]) input_out = np.array(out_dict[&quot;image&quot;]) boxes = np.array(out_dict[&quot;bboxes&quot;]) labels = np.array(out_dict[&quot;class_labels&quot;]) tar[&quot;boxes&quot;] = boxes tar[&quot;labels&quot;] = labels return input_out, tar . . . . class ... FunctionWrapperDouble . class FunctionWrapperDouble(Repr): &quot;&quot;&quot;A function wrapper that returns a partial for an input-target pair.&quot;&quot;&quot; def __init__( self, function, input: bool = True, target: bool = False, *args, **kwargs, ): self.function = partial(function, *args, **kwargs) self.input = input self.target = target def __call__(self, inp: np.ndarray, tar: dict): if self.input: inp = self.function(inp) if self.target: tar = self.function(tar) return inp, tar . . data transforms . from functools import partial transforms_training = ComposeDouble( [ AlbumentationWrapper(albumentation=A.SmallestMaxSize(max_size=512)), FunctionWrapperDouble(np.moveaxis, source=-1, destination=0), ] ) transforms_validation = ComposeDouble( [ AlbumentationWrapper(albumentation=A.SmallestMaxSize(max_size=1024)), FunctionWrapperDouble(np.moveaxis, source=-1, destination=0), ] ) transforms_test = ComposeDouble( [ AlbumentationWrapper(albumentation=A.SmallestMaxSize(max_size=1024)), FunctionWrapperDouble(np.moveaxis, source=-1, destination=0), ] ) . . torch dataset class . . class ... ObjectDetectionDataSet . __init__ args . paper_list . | transform . | . class ObjectDetectionDataSet(torch.utils.data.Dataset): def __init__(self, paper_list, transform: ComposeDouble = None): self.root = DATASET_DIR self.transform = transform self.collection_object = paper_collection_object( paper_list ) self.paper_object_list = [ paper_object( self.collection_object, paper_name ) for paper_name in self.collection_object.paper_list ] self.page_object_list = self.get_page_object_list() def __getitem__(self, index): page_obj = self.page_object_list[index] page_name = page_obj.jpg_name target_name = page_obj.xml_name page = page_obj.get_RGB() target = page_obj.get_target() image_id = torch.tensor([ index ]) target[&quot;image_id&quot;] = image_id target = { key: value.numpy() for key, value in target.items() } if self.transform == None: trans = [] resize = A.SmallestMaxSize( max_size = 1024, interpolation = 1 ) trans.append( resize ) action = A.Compose(trans) page, target = action(image = np.array(page), target = target) page = torch.from_numpy(np.array(page)).type(torch.float32) target = { key: torch.from_numpy(value).type(torch.int64) for key, value in target.items() } page_tens_permuted_1 = page.permute(0,1,2) page_tens_permuted_2 = page.permute(0,2,1) page_tens_permuted_3 = page.permute(1,0,2) page_tens_permuted_4 = page.permute(1,2,0) page_tens_permuted_5 = page.permute(2,0,1) page_tens_permuted_6 = page.permute(2,1,0) &quot;&quot;&quot; print( &quot; permutations in __getitem__ &quot;, &quot; n&quot;, page_tens_permuted_1.size(), &quot; : &quot;, &quot;(1)&quot;, &quot; n&quot;, page_tens_permuted_2.size(), &quot; : &quot;, &quot;(2)&quot;, &quot; n&quot;, page_tens_permuted_3.size(), &quot; : &quot;, &quot;(3)&quot;, &quot; n&quot;, page_tens_permuted_4.size(), &quot; : &quot;, &quot;(4)&quot;, &quot; n&quot;, page_tens_permuted_5.size(), &quot; : &quot;, &quot;(5)&quot;, &quot; n&quot;, page_tens_permuted_6.size(), &quot; : &quot;, &quot;(6)&quot;, &quot; n&quot; ) print(&quot; n n&quot;) &quot;&quot;&quot; return (page_tens_permuted_5, target, page_name, target_name) def __len__(self): return(len(self.page_object_list)) def make_page_objects_for_paper(self, paper): num_pages = paper.num_pages page_object_list = [] for j in range( num_pages ): page_object_list.append( page_object( paper, j+1 ) ) return page_object_list def get_page_object_list(self): paper_list = self.paper_object_list page_object_list = [] for paper in paper_list: page_objects_for_paper = self.make_page_objects_for_paper( paper ) page_object_list += page_objects_for_paper return page_object_list . . . define and load datasets . (starting from a list of non-empty pages) . We do an $80$-$10$-$10$ percentage split of the data, to be fed into three datasets: . dataset_train . | dataset_val . | dataset_test . | . There are . print(len(INDICES)) . . 381 . such non-empty pages. The above percentages are approximated by the split $305$-$38$-$38$ . The training dataset will be obtained from INDICES by taking a random subset of these indices of size $305$. . TRAIN_INDICES = random.sample(INDICES, 305) val_and_test_INDICES = list( set(INDICES) - set(TRAIN_INDICES) ) VAL_INDICES = random.sample(val_and_test_INDICES, 38) TEST_INDICES = list( set(val_and_test_INDICES) - set(VAL_INDICES)) . . The index sets TRAIN_INDICES, VAL_INDICES, TEST_INDICES each give rise to corresponding sets of paper names, when their entries are used as arguments to PAPER_LIST. These are TRAIN_PAPERS, VAL_PAPERS and TEST_PAPERS defined just below. . TRAIN_PAPERS = [ PAGE_LIST[j] for j in TRAIN_INDICES ] VAL_PAPERS = [ PAGE_LIST[j] for j in VAL_INDICES ] TEST_PAPERS = [ PAGE_LIST[j] for j in TEST_INDICES ] . . define datasets . dataset_train = ObjectDetectionDataSet(TRAIN_PAPERS, transform = True ) dataset_valid = ObjectDetectionDataSet(VAL_PAPERS, transform = True ) dataset_test = ObjectDetectionDataSet(TEST_PAPERS, transform = True ) . . . . . dataset full . dataset_full = ObjectDetectionDataSet([ PAGE_LIST[j] for j in INDICES ], transform = True ) . . dataloaders: dataloader_train, dataloader_valid, dataloader_test . from torch.utils.data import DataLoader dataloader_train = DataLoader( dataset = dataset_train, batch_size = 2, shuffle = True, num_workers = 4, collate_fn = utils.collate_fn, ) dataloader_valid = DataLoader( dataset = dataset_valid, batch_size = 2, shuffle = False, num_workers = 4, collate_fn = utils.collate_fn, ) dataloader_test = DataLoader( dataset = dataset_test, batch_size = 2, shuffle = False, num_workers = 4, collate_fn = utils.collate_fn, ) . . dataloader_full = DataLoader( dataset = dataset_full, batch_size = 1, shuffle = False, num_workers = 0, collate_fn = utils.collate_fn, ) . . hyperparameters, logging . params = { &quot;AUTHOR&quot;: &quot;the-ninth-wave&quot;, # &quot;SAVE_DIR&quot;: None, &quot;CLASSES&quot;: 2, &quot;SEED&quot;: 42, &quot;PROJECT&quot;: &quot;math-papers-with-Faster-RCNN&quot;, &quot;EXPERIMENT&quot;: &quot;math-papers-with-Faster-RCNN-EX-3&quot;, &quot;MAXEPOCHS&quot;: 50, } . . !pip install livelossplot --quiet . from livelossplot import PlotLosses liveloss = PlotLosses() ll_train_dict = {} ll_val_dict = {} ll_test_dict = {} . metrics . !git clone https://github.com/johschmidt42/PyTorch-Object-Detection-Faster-RCNN-Tutorial.git . Cloning into &#39;PyTorch-Object-Detection-Faster-RCNN-Tutorial&#39;... remote: Enumerating objects: 265, done. remote: Counting objects: 100% (265/265), done. remote: Compressing objects: 100% (179/179), done. remote: Total 265 (delta 123), reused 224 (delta 82), pack-reused 0 Receiving objects: 100% (265/265), 3.74 MiB | 1.03 MiB/s, done. Resolving deltas: 100% (123/123), done. . ls . coco_eval.py __pycache__/ utils.py coco_utils.py PyTorch-Object-Detection-Faster-RCNN-Tutorial/ vision/ drive/ sample_data/ engine.py transforms.py . cd PyTorch-Object-Detection-Faster-RCNN-Tutorial/ . /content/PyTorch-Object-Detection-Faster-RCNN-Tutorial . ls . anchor_script.ipynb README.md annotation_script.ipynb rename_files_script.ipynb dataset_exploration_script.ipynb setup.py inference_script.ipynb training_script.ipynb pytorch_faster_rcnn_tutorial/ training_script.py . import pytorch_faster_rcnn_tutorial from pytorch_faster_rcnn_tutorial.metrics.enumerators import MethodAveragePrecision from pytorch_faster_rcnn_tutorial.metrics.pascal_voc_evaluator import get_pascalvoc_metrics from pytorch_faster_rcnn_tutorial.utils import from_dict_to_boundingbox . cd .. . /content . ls . coco_eval.py __pycache__/ utils.py coco_utils.py PyTorch-Object-Detection-Faster-RCNN-Tutorial/ vision/ drive/ sample_data/ engine.py transforms.py . lightning module . . class ... FasterRCNN_lightning . args of __init__ . model | . from itertools import chain class FasterRCNN_lightning(pl.LightningModule): def __init__(self, model): super().__init__() self.model = model self.num_classes = 2 def forward(self, x): self.model.eval() return self.model(x) def training_step(self, batch, batch_idx): x, y, x_name, y_name = batch loss_dict_train = self.model(x,y) loss_train = sum(loss for loss in loss_dict_train.values()) if not math.isfinite(loss_train): print(&quot;Loss is {}, stopping training&quot;.format(loss_train)) sys.exit(1) self.log_dict(loss_dict_train) return loss_train def validation_step(self, batch, batch_idx): x, y, x_name, y_name = batch preds = self.model(x) gt_boxes = [ from_dict_to_boundingbox(target, name = name, groundtruth = True) for target, name in zip(y, x_name) ] gt_boxes = list(chain(*gt_boxes)) pred_boxes = [ from_dict_to_boundingbox(pred, name=name, groundtruth=False) for pred, name in zip(preds, x_name) ] pred_boxes = list(chain(*pred_boxes)) return {&quot;pred_boxes&quot;: pred_boxes, &quot;gt_boxes&quot;: gt_boxes} def validation_epoch_end(self, outs): gt_boxes = [out[&quot;gt_boxes&quot;] for out in outs] gt_boxes = list(chain(*gt_boxes)) pred_boxes = [out[&quot;pred_boxes&quot;] for out in outs] pred_boxes = list(chain(*pred_boxes)) metric = get_pascalvoc_metrics( gt_boxes = gt_boxes, det_boxes = pred_boxes, iou_threshold = .5, method = MethodAveragePrecision.EVERY_POINT_INTERPOLATION, generate_table = True, ) per_class, mAP = metric[&quot;per_class&quot;], metric[&quot;mAP&quot;] self.log(&quot;Validation_mAP&quot;, mAP) for key, value in per_class.items(): self.log(f&quot;Validation_AP_{key}&quot;, value[&quot;AP&quot;]) def test_step(self, batch, batch_idx): x, y, x_name, y_name = batch # Inference preds = self.model(x) gt_boxes = [ from_dict_to_boundingbox(target, name=name, groundtruth=True) for target, name in zip(y, x_name) ] gt_boxes = list(chain(*gt_boxes)) pred_boxes = [ from_dict_to_boundingbox(pred, name=name, groundtruth=False) for pred, name in zip(preds, x_name) ] pred_boxes = list(chain(*pred_boxes)) return {&quot;pred_boxes&quot;: pred_boxes, &quot;gt_boxes&quot;: gt_boxes} def test_epoch_end(self, outs): gt_boxes = [out[&quot;gt_boxes&quot;] for out in outs] gt_boxes = list(chain(*gt_boxes)) pred_boxes = [out[&quot;pred_boxes&quot;] for out in outs] pred_boxes = list(chain(*pred_boxes)) metric = get_pascalvoc_metrics( gt_boxes=gt_boxes, det_boxes=pred_boxes, iou_threshold=self.iou_threshold, method=MethodAveragePrecision.EVERY_POINT_INTERPOLATION, generate_table=True, ) per_class, mAP = metric[&quot;per_class&quot;], metric[&quot;mAP&quot;] self.log(&quot;Test_mAP&quot;, mAP) for key, value in per_class.items(): self.log(f&quot;Test_AP_{key}&quot;, value[&quot;AP&quot;]) def configure_optimizers(self): model_params = [p for p in self.model.parameters() if p.requires_grad] optimizer = torch.optim.SGD( model_params, lr = 0.005, momentum = 0.9, weight_decay = 0.0005 ) if self.current_epoch == 0: warmup_factor = 1. / 1000 warmup_iters = min(1000, len(dataloader_train) - 1) lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor) else: lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 3, gamma = 0.1); return { &quot;optimizer&quot;: optimizer, &quot;lr_scheduler&quot;: lr_scheduler } . . class methods . forward( self, x ) | training_step( self, batch, batch_idx ) | validation_step( self, batch, batch_idx ) | . test_step( self, batch, batch_idx ) | configure_optimizers( self ) | . . training setup . from pytorch_lightning import Trainer from pytorch_lightning import seed_everything from pytorch_lightning.callbacks import ( ModelCheckpoint, LearningRateMonitor, EarlyStopping, ) . logging w/ neptune . #from pytorch_lightning.loggers.neptune import NeptuneLogger . . #api_key=&quot;&quot; #import neptune.new as neptune #run = neptune.init( # project = &quot;the-ninth-wave/math-papers-with-Faster-RCNN&quot;, # api_token = api_key #) #neptune_logger = NeptuneLogger( # api_key = api_key, # project_name = f&#39;{params[&quot;AUTHOR&quot;]}/{&quot;math-papers-with-Faster-RCNN&quot;}&#39;, # use your neptune name here # experiment_name = params[&quot;EXPERIMENT&quot;], # params = params, #) #assert neptune_logger.name . . lightning init . task = FasterRCNN_lightning( model ) . callbacks . learningrate_callback = LearningRateMonitor( logging_interval = &quot;step&quot;, log_momentum = False ) . . trainer init . trainer = Trainer( gpus = 1, callbacks = [learningrate_callback], log_every_n_steps = 1, max_epochs = params[&quot;MAXEPOCHS&quot;], ) #logger = neptune_logger, . . GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs . training . start training . trainer.fit( task, train_dataloader = dataloader_train, val_dataloaders = dataloader_valid ) . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params - 0 | model | FasterRCNN | 41.3 M - 41.1 M Trainable params 222 K Non-trainable params 41.3 M Total params 165.197 Total estimated model params size (MB) . end training . saving the model . torch.save( model.state_dict(), &#39;model_weights_7_50e_lightning.tar&#39;) . loading the last model . We now load a previously saved model. The models are saved in the same directory as this notebook, which we now switch to: . most recent model : model_weights_7_50e_lightning . ls . coco_eval.py __pycache__/ utils.py coco_utils.py PyTorch-Object-Detection-Faster-RCNN-Tutorial/ vision/ drive/ sample_data/ engine.py transforms.py . We first load state dictionaries, and initialize the three models. . num_classes = 2 state_dict_last = torch.load(&quot;drive/Othercomputers/Normandie/GitHub/pytorch/vision/vision_projects/math_papers/model_weights_7_50e_lightning.tar&quot;) model_last = get_fasterRCNN( num_classes ) model_last.load_state_dict( state_dict_last ) . . &lt;All keys matched successfully&gt; . display parameters . display_dict_last = { &quot;tint&quot; : (128, 128, 255), # &quot;trans&quot; : .2, # degree of transparency &quot;outline&quot; : (128, 128, 255), &quot;width&quot; : 1 } display_dict_GT = { &quot;tint&quot;: (128,128,128), # grey &quot;trans&quot; : .1, # degree of transparency &quot;outline&quot; : (0,0,0), # black &quot;width&quot; : 3 } . . The next methods allows us to visualize the effect of postprocessing guesses with margin information. . . method ... return_margins . args . page : PIL image | . def return_margins(page): pg = page pg_np = np.array(pg) color_min = np.amin( pg_np, axis =2 ) width_min = np.amin( color_min, axis = 0) def f(x): x_norm = x / 255 return 1 - x_norm normalized = [ f(x) for x in width_min ] L = len(normalized) indices = range(L) j, k = 0, 0 while j &lt; L: if normalized[j] &gt; .1: break j += 1 while k &lt; L: if normalized[L - k - 1] &gt; .1: break k += 1 left_margin = j right_margin = L - k -1 return left_margin , right_margin . . return $ quad$ [left_margin, right_margin] . . to visualize . device = torch.device(&#39;cuda&#39;) if torch.cuda.is_available() else torch.device(&#39;cpu&#39;) . . method ... view_model_prediction . args . model | dataset | index | display_dict | . display_dict_GT | display_size | postprocess | . def view_model_prediction(model, dataset, index, display_dict, display_dict_GT, display_size, thresh = .95, postprocess=True): &quot;&quot;&quot;display calibration&quot;&quot;&quot; ## parameters for ground truth: # tint_GT = display_dict_GT[&quot;tint&quot;] trans_GT = display_dict_GT[&quot;trans&quot;] opacity_GT = int( 255 * trans_GT ) outline_GT = display_dict_GT[&quot;outline&quot;] width_GT = display_dict_GT[&quot;width&quot;] ## parameters for model: # tint = display_dict[&quot;tint&quot;] trans = display_dict[&quot;trans&quot;] opacity = int( 255 * trans ) outline = display_dict[&quot;outline&quot;] width = display_dict[&quot;width&quot;] img, target, img_name, target_name = dataset[index] model.to(device) model.eval() with torch.no_grad(): prediction = model([img.to(device)]) boxes = prediction[0][&quot;boxes&quot;] scores = prediction[0][&quot;scores&quot;] ds_page_list = dataset.page_object_list page_obj = ds_page_list[index] page = page_obj.get_RGB() page_np = np.array(page) H = page_np.shape[1] W = page_np.shape[0] page_pil = Image.fromarray(page_np) xmin, xmax = return_margins(page_pil) boxes_cpu = boxes.cpu() boxes_np = np.array(boxes_cpu) if postprocess == True: for box in boxes_np: box[0] = xmin box[2] = xmax overlay_GT = Image.new(&#39;RGBA&#39;, (H,W), tint_GT + (0,)) overlay = Image.new(&#39;RGBA&#39;, (H,W), tint + (0,)) draw_GT = ImageDraw.Draw(overlay_GT) draw = ImageDraw.Draw(overlay) boxes_GT = target[&quot;boxes&quot;] L_GT = len(boxes_GT) for j in range(0,L_GT): x, y, w, h = boxes_GT[j] shape = [x,y,w,h] draw_GT.rectangle(shape, fill = tint_GT + ( opacity_GT, ), outline = outline_GT, width = width_GT) L = len(boxes_np) for j in range(0,L): if scores[j] &gt;= thresh: x, y, w, h = boxes_np[j] shape = [x, y, w, h] draw.rectangle(shape, fill = tint + ( opacity, ), outline = outline, width = width) intermed = Image.alpha_composite(overlay_GT, overlay ) last = Image.alpha_composite(page_pil.convert(&quot;RGBA&quot;), intermed ) ds = display_size fig = plt.figure(figsize = ds ) f_rows, f_cols = 1, 1 fig.add_subplot( f_rows, f_cols, 1 ) plt.tick_params(left=False,bottom=False) plt.axis(&#39;off&#39;) plt.imshow(last) . . . index = 0 view_model_prediction(model_last, dataset_full, index, display_dict_last, display_dict_GT, (20,20), thresh = .80, postprocess=True) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt;",
            "url": "https://the-ninth-wave.github.io/vision-projects/jupyter/2021/10/21/math-papers-v17.html",
            "relUrl": "/jupyter/2021/10/21/math-papers-v17.html",
            "date": " • Oct 21, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://the-ninth-wave.github.io/vision-projects/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://the-ninth-wave.github.io/vision-projects/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}